# 🚢 Titanic Logistic Regression Project
Exploring and Learning Logistic Regression using the Titanic dataset to predict passenger survival.

## 📄 Files
- **titanic.csv**: Dataset containing information about Titanic passengers.
- **Logistic.py**: Python script for data preprocessing, model building, and evaluation.
- **Report_Logistic.docx**: Written report explaining data visualization, model perforamce and results.
  
## 🎥 Explanation Video: [Click to watch!](https://drive.google.com/file/d/14NQIrYgQp2Nw0yGObTwdtU0IWjIZfAIj/view?usp=sharing)

## 🔍 Data Exploration
The first step involves loading the Titanic dataset and exploring its structure.

### Steps:
1. **📥 Data Loading**: Load the Titanic dataset from a CSV file.
2. **🔍 Data Overview**: Display the first few rows, dataset shape, column names, and summary information.
3. **🚫 Handling Missing Values**: Count and handle missing values in the dataset.
4. **🔢 Unique Values**: Identify the number of unique values in key columns.
5. **🗑️ Dropping Unwanted Columns**: Drop columns that are not useful for the analysis.

## 📊 Data Visualization
Visualizing the data to gain insights.

### Steps:
1. **📊 Bar Graphs**: Plot bar graphs to show survival rates based on different features.
2. **🔢 Convert Categorical to Numeric**: Convert categorical variables (Sex, Embarked) to numeric using one-hot encoding.
3. **🖼️ Scatter Matrix**: Plot a scatter matrix to visualize relationships between features.
4. **🔧 Preprocessing**: Fill missing values in the Age column with the mean age and normalize the data.
5. **📊 Histogram**: Display data distribution and relationship between features.

### Visualizations:
- **Bar Graphs**:  
  ![bar1](https://github.com/maharsh3133/logistic-regresssion/assets/35959045/4543edc0-78c0-437c-bac7-292d03fc079e)
  ![bar2](https://github.com/maharsh3133/logistic-regresssion/assets/35959045/f693dc66-8540-433b-98b2-a731f0897dd1)

- **Scatter Matrix**:
  ![scatter](https://github.com/maharsh3133/logistic-regresssion/assets/35959045/7754fa38-1f69-43f1-a44d-8d367b0e86b3)

- **Histogram**:
  ![hist](https://github.com/maharsh3133/logistic-regresssion/assets/35959045/f36aff1f-e181-434d-ac27-2768ec8b57a9)

## 🏗️ Model Building and Evaluation
Building and evaluating the logistic regression model.

### Steps:
1. **🔄 Train-Test Split**: Split the data into training and testing sets.
2. **🧠 Model Training**: Train a logistic regression model.
3. **📈 Model Evaluation**: Evaluate the model using cross-validation scores and accuracy metrics.
4. **🔍 Predictions and Thresholds**: Make predictions with different probability thresholds (0.5 and 0.75).
5. **📉 Confusion Matrix**: Generate confusion matrices and classification reports for different thresholds.

### Results:
- **Model Coefficients**: Display the coefficients of the trained logistic regression model.
- **Cross-Validation Scores**: Show the mean, max, and min scores from cross-validation.
- **Accuracy Scores**: Compare accuracy scores for different thresholds (0.5 and 0.75).
- **Confusion Matrices**: Display confusion matrices for different thresholds.
- **Classification Reports**: Provide classification reports for different thresholds.

### Model Performance:
- **Accuracy (0.5 threshold)**: `0.783`
- **Accuracy (0.75 threshold)**: `0.735`

### Conclusion:
- The logistic regression model performed reasonably well with an accuracy of around 78% on the test data. The model's performance varies with the threshold value, impacting precision and recall for different classes. Further improvements can be made by exploring more advanced algorithms and feature engineering techniques.

## 👤 Author
- [Maharsh](https://www.linkedin.com/in/maharsh-patel-641777168/)

## 🚀 How to Use
1. Clone the repository: `git clone https://github.com/maharsh3133/logistic-regresssion.git`
2. Navigate to the project directory: `cd logistic-regresssion`
3. Run the script: `python Logistic.py` (install required packages as needed)
4. Explore the results and visualizations generated by the script.

---

This README provides a detailed overview of the project, guiding users through the steps of data exploration, visualization, model building, and evaluation. The inclusion of visualizations and clear descriptions of each step helps in understanding the entire process. Also there is a video explination of the code.
